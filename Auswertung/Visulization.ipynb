{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to 'processed_model_data.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from file\n",
    "with open('OpenVLM.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the required information\n",
    "results = data['results']\n",
    "\n",
    "# Prepare data for export\n",
    "export_data = []\n",
    "\n",
    "for model_name, model_data in results.items():\n",
    "    meta = model_data['META']\n",
    "    model_info = {\n",
    "        \"Model\": model_name,\n",
    "        \"Source\": meta['Method'][1],\n",
    "        \"Parameters\": meta['Parameters'],\n",
    "        \"Time\": meta['Time'],\n",
    "        \"OpenSource\": meta['OpenSource']\n",
    "    }\n",
    "    \n",
    "    # Collect Overall scores for each test\n",
    "    for test_name, test_data in model_data.items():\n",
    "        if test_name != 'META' and 'Overall' in test_data:\n",
    "            overall_score = test_data['Overall']\n",
    "            if isinstance(overall_score, str):\n",
    "                # Handle cases like \"62.3 (PPL)\"\n",
    "                overall_score = float(overall_score.split()[0])\n",
    "            model_info[f\"{test_name} Overall\"] = overall_score\n",
    "    \n",
    "    export_data.append(model_info)\n",
    "\n",
    "# Export to JSON\n",
    "with open('processed_model_data.json', 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(\"Data exported to 'processed_model_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models:  92\n"
     ]
    }
   ],
   "source": [
    "#count number of models\n",
    "print(\"Number of models: \", len(export_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced data exported to 'reduced_model_data.json'\n",
      "Reduced data exported to 'reduced_model_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Load the JSON data from file\n",
    "with open('processed_model_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define the fields we want to keep and their new names\n",
    "fields_to_keep = {\n",
    "    'Model': 'Model',\n",
    "    'Parameters': 'ModelSize',\n",
    "    'OpenSource': 'OpenSource',\n",
    "    'TextVQA_VAL Overall': 'TextVQA',\n",
    "    'POPE Overall': 'POPE',\n",
    "    'AI2D Overall': 'AI2D',\n",
    "    'ChartQA_TEST Overall': 'ChartQA',\n",
    "    'ScienceQA_TEST Overall': 'ScienceQA',\n",
    "    'MMMU_VAL Overall': 'MMMU',\n",
    "    'MMBench_TEST_EN Overall': 'MMBench',\n",
    "    'MathVista Overall': 'MathVista'\n",
    "}\n",
    "\n",
    "# Prepare reduced data\n",
    "reduced_data = []\n",
    "\n",
    "for item in data:\n",
    "    reduced_item = {}\n",
    "    scores = []\n",
    "    for old_key, new_key in fields_to_keep.items():\n",
    "        if old_key in item:\n",
    "            value = item[old_key]\n",
    "            reduced_item[new_key] = value\n",
    "            if new_key not in ['Model', 'ModelSize', 'OpenSource'] and value != 'N/A':\n",
    "                try:\n",
    "                    scores.append(float(value))\n",
    "                except ValueError:\n",
    "                    pass  # Ignore if conversion to float fails\n",
    "        else:\n",
    "            reduced_item[new_key] = 'N/A'\n",
    "    \n",
    "    # Calculate average score\n",
    "    if scores:\n",
    "        reduced_item['AverageScore'] = sum(scores) / len(scores)\n",
    "    else:\n",
    "        reduced_item['AverageScore'] = 'N/A'\n",
    "    \n",
    "    reduced_data.append(reduced_item)\n",
    "\n",
    "# Export to JSON\n",
    "with open('reduced_model_data.json', 'w') as f:\n",
    "    json.dump(reduced_data, f, indent=2)\n",
    "\n",
    "print(\"Reduced data exported to 'reduced_model_data.json'\")\n",
    "\n",
    "# Export to CSV\n",
    "with open('reduced_model_data.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(fields_to_keep.values()) + ['AverageScore'])\n",
    "    writer.writeheader()\n",
    "    for item in reduced_data:\n",
    "        writer.writerow(item)\n",
    "\n",
    "print(\"Reduced data exported to 'reduced_model_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
