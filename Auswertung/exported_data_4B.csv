Model,ModelSize,TextVQA,POPE,AI2D,ChartQA,ScienceQA,MMMU,MMBench,MathVista,AverageScore
"InternVL2-2B","2","73.4","85.2","74.1","71.7","94.1","36.3","73.4","46","69.28"
"InternLM-XComposer2-1.8B","2","N/A","84.2","71.1","N/A","92.2","29.7","73","50.1","66.72"
"Mini-InternVL-Chat-2B-V1.5","2","N/A","85.4","69.7","N/A","84.8","37.4","70.7","41.3","64.88"
"InternVL2-1B","1","70.9","84.9","63.8","67.8","87.9","36.7","65.2","39.4","64.58"
"MiniCPM-V-2","2.8","73.2","86.3","62.9","55.6","80.7","38.2","69.1","39.8","63.23"
"PaliGemma-3B-mix-448","3","68.1","87.5","68.3","33.7","94.3","34.9","71","28.7","60.81"
"MiniCPM-V","3","56.6","79.5","56.3","44.2","77","38.3","64.1","30.6","55.83"
"DeepSeek-VL-1.3B","2.0","57.8","85.9","51.5","47.4","68.4","33.8","66.4","29.8","55.13"
