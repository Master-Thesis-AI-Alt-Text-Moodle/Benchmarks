{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\cuda_test\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 01.jpg\n",
      "Processed 02.jpg\n",
      "Processed 03.jpg\n",
      "Processed 04.jpg\n",
      "Processed 05.jpg\n",
      "Processed 06.png\n",
      "Processed 07.png\n",
      "Processed 08.png\n",
      "Processed 09.png\n",
      "Processed 10.png\n",
      "Processed 11.png\n",
      "Processed 12.png\n",
      "Processed 13.png\n",
      "Processed 14.jpg\n",
      "Processed 15.png\n",
      "Processed 15 images\n",
      "Total processing time: 3.59 seconds\n",
      "Average time per image: 0.24 seconds\n",
      "Total input tokens: 2257920\n",
      "Total output tokens: 189\n",
      "Average input tokens per image: 150528.00\n",
      "Average output tokens per image: 12.60\n",
      "Results saved to C:\\Users\\Patrick\\Documents\\thesis\\Dataset\\Results\\vit-gpt2_cuda_analysis_results.json\n",
      "Running benchmark on cpu\n",
      "Processed 01.jpg\n",
      "Processed 02.jpg\n",
      "Processed 03.jpg\n",
      "Processed 04.jpg\n",
      "Processed 05.jpg\n",
      "Processed 06.png\n",
      "Processed 07.png\n",
      "Processed 08.png\n",
      "Processed 09.png\n",
      "Processed 10.png\n",
      "Processed 11.png\n",
      "Processed 12.png\n",
      "Processed 13.png\n",
      "Processed 14.jpg\n",
      "Processed 15.png\n",
      "Processed 15 images\n",
      "Total processing time: 15.80 seconds\n",
      "Average time per image: 1.05 seconds\n",
      "Total input tokens: 2257920\n",
      "Total output tokens: 189\n",
      "Average input tokens per image: 150528.00\n",
      "Average output tokens per image: 12.60\n",
      "Results saved to C:\\Users\\Patrick\\Documents\\thesis\\Dataset\\Results\\vit-gpt2_cpu_analysis_results.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "\n",
    "# Define paths\n",
    "DATASET_PATH = r\"C:\\Users\\Patrick\\Documents\\thesis\\Dataset\\OwnDataSet\"\n",
    "RESULTS_PATH = r\"C:\\Users\\Patrick\\Documents\\thesis\\Dataset\\Results\"\n",
    "\n",
    "def load_model_and_processors(device):\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").to(device)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    return model, feature_extractor, tokenizer\n",
    "\n",
    "def process_images(model, feature_extractor, tokenizer, dataset_path, device):\n",
    "    results = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(dataset_path, filename)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "            \n",
    "            # Generate description\n",
    "            with torch.no_grad():\n",
    "                output = model.generate(pixel_values, max_length=35, num_return_sequences=1)\n",
    "            \n",
    "            response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            processing_time = end_time - start_time\n",
    "            input_tokens = pixel_values.numel()\n",
    "            output_tokens = output.numel()\n",
    "            \n",
    "            results.append({\n",
    "                \"filename\": filename,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens,\n",
    "                \"alternative_text\": response\n",
    "            })\n",
    "            \n",
    "            print(f\"Processed {filename}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results(results, output_path, device):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file = os.path.join(output_path, f\"vit-gpt2_{device}_analysis_results.json\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "def run_benchmark(device):\n",
    "    print(f\"Running benchmark on {device}\")\n",
    "    \n",
    "    # Load model and processors\n",
    "    model, feature_extractor, tokenizer = load_model_and_processors(device)\n",
    "\n",
    "    # Process images\n",
    "    results = process_images(model, feature_extractor, tokenizer, DATASET_PATH, device)\n",
    "\n",
    "    # Print summary\n",
    "    total_time = sum(r[\"processing_time\"] for r in results)\n",
    "    total_input_tokens = sum(r[\"input_tokens\"] for r in results)\n",
    "    total_output_tokens = sum(r[\"output_tokens\"] for r in results)\n",
    "    num_images = len(results)\n",
    "    \n",
    "    print(f\"Processed {num_images} images\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per image: {total_time/num_images:.2f} seconds\")\n",
    "    print(f\"Total input tokens: {total_input_tokens}\")\n",
    "    print(f\"Total output tokens: {total_output_tokens}\")\n",
    "    print(f\"Average input tokens per image: {total_input_tokens/num_images:.2f}\")\n",
    "    print(f\"Average output tokens per image: {total_output_tokens/num_images:.2f}\")\n",
    "\n",
    "    # Save results\n",
    "    save_results(results, RESULTS_PATH, device)\n",
    "\n",
    "def main():\n",
    "    # Run benchmark on GPU\n",
    "    if torch.cuda.is_available():\n",
    "        run_benchmark(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Skipping GPU benchmark.\")\n",
    "\n",
    "    # Run benchmark on CPU\n",
    "    run_benchmark(\"cpu\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
